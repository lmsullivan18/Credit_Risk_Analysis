# Credit Risk Analysis

## Overview
The purpose of this analysis was to apply machine learning to the real-world challenge of credit risk. I used different techniques to train and evaluate models with unbalanced classes. Using the analysis of the different techniques, I can make a recommendation as to which model should be used to predict credit risk.

## Results

In the first section we compared Naive Random Oversampling with SMOTE Oversampling.
- The results of the Naive Random Oversampling show that the accuracy score is about 65%. However, the precision when evaluating high risk loans is extremely low. This is not a useful prediction as it is more important in this instance to have a precise model. This is because approving a bad loan is more costly than missing out on the potential profit from a good loan.
- The results of the SMOTE Oversampling are very similar to the native random oversampling. The accuracy is about 61% but the precision when evaluating high rick loans is extremely low.

In the second section we used Undersampling. 
- The results of the undersampling method show are even worse than the two oversampling methods. The accuracy score is lower at 50% and the precision is just as low for predicting high risk loans. 

Then, we used Combination (Over and Under) Sampling.
- The results of combination sampling show that XX.
In the last section we used Ensemble Learning.
- The results of the Balanced Random Forest Classifier
- The results of the Easy Ensamble AdaBoost Classifier 

## Summary
In summary, XX. I recommend using the XX model because XX.
